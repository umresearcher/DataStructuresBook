<?xml version="1.0" encoding="UTF-8"?>

<chapter xml:id="ch-intro-analysis" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Introduction to Algorithm Analysis</title>

  <introduction>
    <p>Why analyze algorithms? (develop arguments from Cormen etc)</p> 
    <p>A learning goal of a 
    computer science education is to be able to compare multiple algorithms (let us call
    them Algorithm <m>A</m> and Algorithm <m>B</m>) that solve a specific problem and 
    choose the "optimal" one. Note that we started by saying: Algorithm <m>A</m> and 
    Algorithm <m>B</m> are both algorithms for the problem. This means that both 
    Algorithm <m>A</m> and Algorithm <m>B</m> will give you the correct solution for any 
    instance of the problem. What makes an algorithm "optimal" could depend on several 
    factors: for instance, it could be time for implementing, testing and maintaining the 
    algorithm, it could be the time it takes for the algorithm to solve the problem, it 
    could be the extra memory that the algorithm uses while solving the problem. 
    </p>

    <p>While you can compare two algorithms across multitude of factors, the time taken for 
    an algorithm to solve a problem is a good starting point, and is often the most useful 
    (validate claim??). Now when we compare the time it takes for two algorithms to solve 
    a problem, we need to also consider the underlying computer system on which the algorithm
    will be run. For instance, a parallel computer can potentially run the statements in 
    an algorithm in parallel whereas a single core processor will run the statements in sequence.
    Also, we could measure the time taken for a parallel computer in multiple ways: it could
    be the sum of the time taken by each processor in the parallel computer (or) it could be 
    the wall clock time it takes from when the parallel computer starts solving the problem 
    till it gives the result. In the second case, two processors running in parallel and each 
    doing 10 seconds of computation in parallel will be considered as taking 10 seconds to 
    solve the problem. While several such variations are possible, a computer science student 
    must know how to analyze the time it takes on a single processor computer. A student with
    this knowledge is well-equipped to analyze the running time under other computer system 
    architectures as well, as needed.
    </p>

    <p>Even across single processor computers, your processor could support different 
    operations. For instance, we have 
    specialized chips for AI (check !!). In that case, an operation that 
    takes several steps on a processor could be done on 1 step on a different architecture. 
    Another example is <m>2^n</m> can be done in one processor by left shift of 1 by <m>n</m> 
    bits, or by looping <m>n</m> times and multiplying by 2 each time. Once again, while 
    these different processor architectures and supported basic operations are important
    for analysis, we will make simplifying assumptions that are commonplace (check claim).  
    </p>

    <p>We have laid out that we need to analyze the running time of an algorithm on a single
    processor computer. But how do we go about it? Let us look at the tools that we have 
    developed over the years to enable such analysis of algorithms.</p>

    <p>So, how to express the running time of an algorithm for a particular input instance
    of a problem? We typically represent this as a function of the input size. And for the 
    input size, we use the number of bits used to represent the input. For instance, 
    if the input is an array of <m>n</m> numbers and each number is represented using 8 bits, 
    the input size is <m>8 \times n</m>, and we represent the running time of an algorithm in 
    terms of this input size. Note that we actually represent the running time in terms of 
    <m>n</m> in this case.
    </p>

    <p>Tool 1: Bounds. We said we want to represent the running time, but how do we represent the running 
    time? Is it milliseconds? then a faster processor might run a less "optimal" algorithm 
    quicker than a slower processor running a more "optimal" algorithm. Our focus is on 
    comparing the algorithms, and not comparing the individual processor quirks. For this, 
    we use bounds -- <m>O</m>, <m>\Omega</m>, <m>\Theta</m>, <m>o</m>, and <m>\omega</m>. These 
    bounds us provide us the ability to ignore the individual processor quirks and compare
    the "optimality" of algorithms.
    </p>

    <p>Tool 2: Asymptotic Analysis.</p>
    <p>How long does it take for an algorithm to complete when the input size is a small
    number, say 5 (for instance array of 5 numbers). Unless your algorithm has an infinite loop, 
    the algorithm will take some small number of steps. Using our bounds, all "reasonable" 
    algorithms take <m>\Theta(1)</m> time for small input sizes. To perform meaningful analysis
    of algorithms, we perform asymptotic analysis - which basically means, we compare how two 
    algorithms perform when the input size is large.</p> 

    <p>Consider the problem of searching if a given key <m>k</m> is present in an array 
    <m>A[1\ldots n]</m>. Consider a simple algorithm where we start from index 1 and loop 
    through all indexes, each time checking if the element at that index is the key <m>k</m>
    that we are searching for. If we find the key <m>k</m>, we can immediately return "success". 
    If we loop through the whole loop and do not find the key <m>k</m>, we return "failure".
    </p>

    <p>What do we note in the above algorithm? First off, we analyze when the input size 
    <m>n</m> is large. How much time does it take? We might get lucky and find that 
    <m>A[1] = k</m>, in which case we return in <m>Theta(1)</m> time. We might get unlucky, 
    and never find <m>k</m>, or find that the last element is <m>k</m> (<m>A[n] = k</m>). How
    do we characterize these different running times depending on "our luck"?
    </p>

    <p>For this, we perform the best case, and worst case analysis. The best case for an 
    algorithm considers the input for which the algorithm will run the fastest. The running 
    time in the best case is called the best case running time for that algorithm. Similarly,
    the worst case for an algorithm considers the input for which the algorithm will run the 
    slowest. The running time in the worst case is called the worst case running time for that 
    algorithm.
    </p>

  </introduction>

  <!-- include sections -->
  <xi:include href="sec-findMin.ptx" />

</chapter>